<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />

    <title></title>
    <link rel="stylesheet" href="dist/reveal.css" />
    <link rel="stylesheet" href="dist/theme/night.css" id="theme" />
    <link rel="stylesheet" href="plugin/highlight/zenburn.css" />
	<link rel="stylesheet" href="css/layout.css" />
	<link rel="stylesheet" href="plugin/customcontrols/style.css">



    <script defer src="dist/fontawesome/all.min.js"></script>

	<script type="text/javascript">
		var forgetPop = true;
		function onPopState(event) {
			if(forgetPop){
				forgetPop = false;
			} else {
				parent.postMessage(event.target.location.href, "app://obsidian.md");
			}
        }
		window.onpopstate = onPopState;
		window.onmessage = event => {
			if(event.data == "reload"){
				window.document.location.reload();
			}
			forgetPop = true;
		}

		function fitElements(){
			const itemsToFit = document.getElementsByClassName('fitText');
			for (const item in itemsToFit) {
				if (Object.hasOwnProperty.call(itemsToFit, item)) {
					var element = itemsToFit[item];
					fitElement(element,1, 1000);
					element.classList.remove('fitText');
				}
			}
		}

		function fitElement(element, start, end){

			let size = (end + start) / 2;
			element.style.fontSize = `${size}px`;

			if(Math.abs(start - end) < 1){
				while(element.scrollHeight > element.offsetHeight){
					size--;
					element.style.fontSize = `${size}px`;
				}
				return;
			}

			if(element.scrollHeight > element.offsetHeight){
				fitElement(element, start, size);
			} else {
				fitElement(element, size, end);
			}		
		}


		document.onreadystatechange = () => {
			fitElements();
			if (document.readyState === 'complete') {
				if (window.location.href.indexOf("?export") != -1){
					parent.postMessage(event.target.location.href, "app://obsidian.md");
				}
				if (window.location.href.indexOf("print-pdf") != -1){
					let stateCheck = setInterval(() => {
						clearInterval(stateCheck);
						window.print();
					}, 250);
				}
			}
	};


        </script>
  </head>
  <body>
    <div class="reveal">
      <div class="slides"><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

# How Machines Think
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

### Introduction

What will we be covering?

- Why our brains are amazing
- How does that inform machine learning?
- What happens when a model answers a question?
- How did it "learn" to answer those questions?


<small> Disclaimer: Lots of this is inspired by [3Blue1Brown](https://www.youtube.com/watch?v=aircAruvnKk) he has a video covering much of what I'll be talking about.</small>
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

### Our Brains Are Amazing

Forget about machine learning for a moment. 

**Goal**: Identify the following images.
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

<img src="Media/Untitled.png" alt="" style="object-fit: scale-down">

Any ideas what we're looking at?
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

How about now?

<img src="Media/nums.png" alt="" style="object-fit: scale-down">
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

## Question: Why was that so much easier?

notes: It seems like a dumb question but I'd argue its pretty profound
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

## 2 Reasons:

- Context
- Pattern Recognition
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

Let's appreciate our brains for a second!

notes: photo cells in the eye stimulate your nervous system, which in turn stimulates neurons in your brain, through a dizzying amount of electro-chemical reaction to somehow inform you that these are numbers
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

Now what if I asked you to write a piece of software to do this task?
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

We're all smart programmers, let's try!
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

What does our data look like? 

<img src="Media/num_breakdown.png" alt="" style="width: 600px; object-fit: fill">


notes: 28x28 image as a 2d array. 0 represents a completely dim pixel, 255 represents a fully lit one -- plotted on a graph looks something like this. Lets hear some ideas for how we'd write an image identifier
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

Let's look at a solution I wrote

<img src="Media/Pasted image 20230813125020.png" alt="" style="object-fit: scale-down">


notes: break out into google colab notebook
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

Question: Is this how your brain solves this problem?

notes: The question you have to ask here to get to machine learning is...
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

Let's use the way the brain works to inform the architecture of our new program.
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

So what **does** our brain do?
</div>

<aside class="notes"><p>we said it before -- visual cortex, central nervous system which triggers our brains to have a set of neurons activate</p>
</aside></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

a *set of* neurons might activate in response to a particular stimulus

<img src="Media/41583_2022_598_Fig1_HTML.png" alt="" style="object-fit: scale-down">


notes: The stimulus pass through our neurons might light up entire regions of the brain with activity. So there's this idea of a cascading signal lighting up particular pathways
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

Brains are complex. 

I don't even really understand that last image.

notes: Since this is complex we need to generalize it to something we can implement. Like many things in software engineering, math is the solution here
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

To simplify, we have lots of data points and we want to find a way to generalize this data

notes: In math when we have some data set and we want to determine given some input, x what will the output y be, we use a function
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

eg: this data generally fits a sine wave

<img src="Media/Pasted image 20230813133027.png" alt="" style="width: 600px; object-fit: fill">


`$y = 3sin(x)$`


notes: so here our best approximation of this data is a Sine wave times 3, so if we input 150 degrees we get roughly 0.5
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

But each image has 784 (`$28\times28$`) inputs!

notes: so the problem here is that we're dealing with what we call high dimensionality. each pixel of the image has to be an input to this function. In machine learning you might call that a "feature"
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

What if we used linear functions?

<img src="Media/Pasted image 20230813131803.png" alt="" style="object-fit: scale-down">


`$y = \sigma(w_1 x_1 + w_2 x_2 + ... +  w_n x_n)$`

notes: if we need a high number of variables, the best solution that comes to mind is a linear system of equations. Here x represents a single pixel and y is if our neuron is activating or not
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

`$y = \sigma(w_1 x_1 + w_2 x_2 + ... +  w_n x_n)$`


### What about `$\large w$`?

notes: we're also going to define this other number, called the weight. It essentially represents how much we want this particular pixel to effect if our neuron becomes active or not.
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

But we have many neurons!

notes: our brains are comprised of 86 billion neurons, so maybe our piece of software should as well, but why? Well the idea is that maybe we'll be able to teach our software to light up particular neurons when it see an image of a 2, and in turn identify it. We'll cover that when we talk about training
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

Let's add more neurons, and while we're at it, lets add some layers too!

<video src="https://giant.gfycat.com/LimpingDarlingFinnishspitz.mp4"></video>

notes: So like before you can imagine that our input layer is taking in each pixel, and then we pass that along to the next layer in this network, which might output a high number for some neurons and a low number for other neurons, and then pass that along, which eventually reaches our last, output layer.
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

<video src="https://thumbs.gfycat.com/HandyBraveAnophelesmosquito-mobile.mp4" ></video>

Intuitively though, why are we using multiple layers like this?

notes: our hope here is that if the first layer sees every pixel, and thus is activated when a pixel is bright or dim, then maybe in the next layer a particular neuron might be active when a specific cluster of pixels is lit, which might represent a piece of a shape, like a loop or a line, and then maybe the next layer will stitch those pieces into a shape like a loop or a line
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

Ok great! lets try it!
<img src="Media/Pasted image 20230813143231.png" alt="" style="object-fit: scale-down">

notes: Break into colab notebook after walking through the code. Keras gives us some nice libraries to represent these layers as objects and call-back functions we can pass to each other
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

I thought these things were supposed to be smart?...

We need to _train_ our network!

<video height=480 src="https://giant.gfycat.com/ContentDarlingCub.mp4" ></video>

notes: we had some trouble... we never trained our network, and just initialized all our weights randomly... what if we start to nudge all the weights a bit so they start to give better results? To do this, we need to know how wrong we are. So, we need a new function, called the "Cost" which helps define how wrong our network is. What if we just take a simple sum of the difference between our expected output and the actual output for our last layer? when that number is small, then we performed well and when its large we performed poorly. Not only can we use this cost function to tell if 1 output is bad, but we can find the average output of the cost function and that should tell us generally how badly the network is performing on any particular training example.
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

We have to tell the network where it went wrong

<video src="https://giant.gfycat.com/EquatorialSpicyEgg.mp4" ></video>

notes: So, if we want the network to perform better, then we need a way to minimize the output of this cost function. If you remember your calculus well, you might remember that there is a way to find the direction of steepest ascent in a function; its called the gradient. Naturally if you wanted to find the opposite you can just take the negative gradient. What we have now is a method to find some set of values that will minimize, or lower, the output of our cost function.
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

So lets try training!

notes: Train the network live, and then show an inference in the Colab notebook.
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

Remember when we talked about our hope for what each layer might do?

notes: earlier in the presentation we spoke about how the hope was that a particular neuron might detect part of a shape, and the next layer would piece those shapes together?
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

Lets actually check if our hope was right

<img src="Media/neural_weights.png" alt="" style="object-fit: scale-down">


notes: this is what the inside of our simple neural network's brain looks like. this is the set of weights for one of our layers with 16 neurons in it. It's pretty easy to see that our hope for how this was going to work, versus how it actually works was way off. Here the dark spots are the parts deemed less important and the brighter spots are where the network is deciding to focus. the shapes we're seeing are more or less random.
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

What we just covered is about 1% of the depth of neural networks.

notes: there is so much to learn here, our example was one of the most basic forms of neural networks, a multilayers perceptron. Modern networks have so many interesting tricks up their sleeve, but the good part is a lot of them are an abstraction on these base concepts, more or less. If you're interested in learning more about this definitely check out 3Blue1Browns videos on this topic, he's way more intelligent than me, and that video goes into way more depth.
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="drop" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 700px; width: 960px; min-height: 700px; display: flex; flex-direction: column; align-items: center; justify-content: center" absolute="true">

If you want to play with the notebook / code from this presentation: 

<img src="Media/Machine_learning_Colab.png" alt="" style="width: 400px; object-fit: fill">


Or go to:
https://www.github.com/m-triassi/machine-learning-basics
</div></script></section></div>
    </div>

    <script src="dist/reveal.js"></script>

    <script src="plugin/markdown/markdown.js"></script>
    <script src="plugin/highlight/highlight.js"></script>
    <script src="plugin/zoom/zoom.js"></script>
    <script src="plugin/notes/notes.js"></script>
    <script src="plugin/math/math.js"></script>
	<script src="plugin/mermaid/mermaid.js"></script>
	<script src="plugin/chart/chart.min.js"></script>
	<script src="plugin/chart/plugin.js"></script>
	<script src="plugin/customcontrols/plugin.js"></script>

    <script>
      function extend() {
        var target = {};
        for (var i = 0; i < arguments.length; i++) {
          var source = arguments[i];
          for (var key in source) {
            if (source.hasOwnProperty(key)) {
              target[key] = source[key];
            }
          }
        }
        return target;
      }

	  function isLight(color) {
		let hex = color.replace('#', '');

		// convert #fff => #ffffff
		if(hex.length == 3){
			hex = `${hex[0]}${hex[0]}${hex[1]}${hex[1]}${hex[2]}${hex[2]}`;
		}

		const c_r = parseInt(hex.substr(0, 2), 16);
		const c_g = parseInt(hex.substr(2, 2), 16);
		const c_b = parseInt(hex.substr(4, 2), 16);
		const brightness = ((c_r * 299) + (c_g * 587) + (c_b * 114)) / 1000;
		return brightness > 155;
	}

	var bgColor = getComputedStyle(document.documentElement).getPropertyValue('--r-background-color').trim();
	var isLight = isLight(bgColor);

	if(isLight){
		document.body.classList.add('has-light-background');
	} else {
		document.body.classList.add('has-dark-background');
	}

      // default options to init reveal.js
      var defaultOptions = {
        controls: true,
        progress: true,
        history: true,
        center: true,
        transition: 'default', // none/fade/slide/convex/concave/zoom
        plugins: [
          RevealMarkdown,
          RevealHighlight,
          RevealZoom,
          RevealNotes,
          RevealMath.MathJax3,
		  RevealMermaid,
		  RevealChart,
		  RevealCustomControls,
        ],


    	allottedTime: 120 * 1000,

		mathjax3: {
			mathjax: 'plugin/math/mathjax/tex-mml-chtml.js',
		},
		markdown: {
		  gfm: true,
		  mangle: true,
		  pedantic: false,
		  smartLists: false,
		  smartypants: false,
		},

		mermaid: {
			theme: isLight ? 'default' : 'dark',
		},

		customcontrols: {
			controls: [
			]
		},
      };

      // options from URL query string
      var queryOptions = Reveal().getQueryHash() || {};

      var options = extend(defaultOptions, {"width":960,"height":700,"margin":0.04,"controls":true,"progress":true,"slideNumber":false,"transition":"none","transitionSpeed":"default"}, queryOptions);
    </script>

    <script>
      Reveal.initialize(options);
    </script>
  </body>

  <!-- created with Advanced Slides -->
</html>
